import pytest
from unittest.mock import MagicMock, patch
from datetime import datetime

import importlib.util

def load_delta_module():
    spec = importlib.util.spec_from_file_location("delta_module", "bin/03_check_delta_files.py")
    module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(module)
    return module

def test_process_check_delta_files_returns_urls():
    module = load_delta_module()
    dummy_output = {"internal": {"en": [{"url": "http://example.com"}]}}
    mock_db = MagicMock()

    with patch.object(module.DocumentList, "get_urls_by_hash", return_value=dummy_output):
        result = module.process_check_delta_files("internal", "en", mock_db, "etl")
        assert result == dummy_output

def test_update_document_change_history_inserts_and_updates():
    module = load_delta_module()
    mock_db = MagicMock()
    hash_changes = {
        123: {"old_hash": "abc", "new_hash": "def"},
        456: {"old_hash": None, "new_hash": "ghi"},  # should be skipped
    }

    module.update_document_change_history(mock_db, hash_changes, etl_schema="etl")

    # Validate INSERT and UPDATE queries were called
    assert mock_db.executeQuery.call_count >= 3




def test_load_file_download_meta_json():
    import json
    from unittest.mock import mock_open, patch

    dummy_data = {"http://example.com/sample.pdf": {"url": "http://example.com/sample.pdf", "hash_256": "abc123"}}
    mock_data = json.dumps(dummy_data)

    with patch("builtins.open", mock_open(read_data=mock_data)):
        with open("/tmp/file_download_meta.json", "r") as f:
            loaded_data = json.load(f)

    assert isinstance(loaded_data, dict)
    assert "http://example.com/sample.pdf" in loaded_data



def test_directory_traversal_and_hash_logic():
    import json
    from unittest.mock import patch, mock_open
    from KMAI.ingestion import DocumentList

    dummy_file_metadata = {
        "http://example.com/sample.pdf": {"url": "http://example.com/sample.pdf", "hash_256": "abc123"}
    }
    dummy_url_info = {"hash_256": "abc123", "url": "http://example.com/sample.pdf"}

    with patch("os.walk") as mockwalk, \
         patch("os.path.splitext", side_effect=lambda f: ("sample", ".pdf")), \
         patch.object(DocumentList, "get_file_hash", return_value="abc123"), \
         patch("builtins.open", mock_open(read_data=json.dumps(dummy_file_metadata))):

        mockwalk.return_value = [("/tmp/internal/en", [], ["sample.pdf", "file.meta.json"])]

        not_required_files = []
        required_files = []

        url_list = {"sample": dummy_url_info}
        basedir = "/tmp/internal/en"
        filename = "sample.pdf"
        first_part_filename = "sample"

        if filename.endswith("meta.json"):
            pass
        elif first_part_filename not in url_list:
            not_required_files.append((f"{basedir}/{filename}", "is not in URL files list"))
        else:
            file_hash_256 = DocumentList.get_file_hash(f"{basedir}/{filename}")
            required_file_metadata = dummy_file_metadata.get(url_list[first_part_filename]["url"])
            if url_list[first_part_filename]["hash_256"] == file_hash_256:
                not_required_files.append((f"{basedir}/{filename}", "Hash Same"))
            elif required_file_metadata and required_file_metadata not in required_files:
                required_files.append(required_file_metadata)

    assert len(not_required_files) == 1
    assert "Hash Same" in not_required_files[0][1]


def test_main_loop_with_mocked_config_and_json():
    import json
    from unittest.mock import patch, mock_open, MagicMock
    from KMAI.ingestion import DocumentList

    dummy_config = {
        "sql_db": {"server_name": "server", "db_name": "db", "etl_schema": "etl"},
        "credentials": {"object_id": "uid"},
        "processing": {
            "log_dir": "/tmp/logs",
            "output_dir": "/tmp/output"
        },
        "document_scopes": {
            "classification": ["internal"],
            "language": ["en"],
            "document_change_history": "false"
        }
    }

    dummy_url_info = {
        "internal": {
            "en": {
                "sample": {
                    "url": "http://example.com/sample.pdf",
                    "hash_256": "abc123"
                }
            }
        }
    }

    dummy_file_metadata = {
        "http://example.com/sample.pdf": {"url": "http://example.com/sample.pdf", "hash_256": "abc123"}
    }

    with patch("WGPT.Utilities.read_config", return_value=dummy_config), \
         patch("os.walk") as mockwalk, \
         patch("builtins.open", mock_open(read_data=json.dumps(dummy_file_metadata))), \
         patch.object(DocumentList, "get_file_hash", return_value="abc123"), \
         patch("os.remove") as mock_remove:

        mockwalk.return_value = [("/tmp/output/internal/en", [], ["sample.pdf"])]

        # Simulate the main loop
        output_dir = "/tmp/output/internal/en"
        file_meta_json = f"{output_dir}/file_download_meta.json"
        with open(file_meta_json, "r") as f:
            file_metadata = json.load(f)

        basedir = "/tmp/output/internal/en"
        filename = "sample.pdf"
        first_part_filename = "sample"
        url_list = dummy_url_info["internal"]["en"]

        not_required_files = []
        required_files = []

        file_hash_256 = DocumentList.get_file_hash(f"{basedir}/{filename}")
        if url_list[first_part_filename]["hash_256"] == file_hash_256:
            not_required_files.append((f"{basedir}/{filename}", "Hash Same"))

    assert "Hash Same" in not_required_files[0][1]
